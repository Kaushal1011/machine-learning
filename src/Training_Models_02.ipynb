{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Models 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contents \n",
    "\n",
    "- Ensemble Methods\n",
    "    - Voting Classifier\n",
    "    - Bagging vs Pasting\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Voting Classifier\n",
    "\n",
    "If we have multiple classifiers each acheiving some accuracy and we want to create an even better classifier we use the voting classifier to predict based on predictions of our previously trained classifiers.\n",
    "I hope this image explains this in a better way.\n",
    "\n",
    "![Ensemble](img/ensemble1.png)\n",
    "\n",
    "![Ensemble](img/ensemble2.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___Hard Voting Classifier___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Ensemble methods work best when the predictors are as independ‐\n",
    "ent from one another as possible. One way to get diverse classifiers\n",
    "is to train them using very different algorithms. This increases the\n",
    "chance that they will make very different types of errors, improving\n",
    "the ensemble’s accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sklearn Example\n",
    "\n",
    "\n",
    "```python\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "log_clf = LogisticRegression()\n",
    "rnd_clf = RandomForestClassifier()\n",
    "svm_clf = SVC()\n",
    "voting_clf = VotingClassifier(\n",
    " estimators=[('lr', log_clf), ('rf', rnd_clf), ('svc', svm_clf)],\n",
    " voting='hard'\n",
    " )\n",
    "voting_clf.fit(X_train, y_train)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bagging vs Pasting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another approach is to use the same training algorithm for every\n",
    "predictor, but to train them on different random subsets of the training set.\n",
    "\n",
    "__When sampling is performed with replacement, this method is called bagging\n",
    " (short for\n",
    "bootstrap aggregating\n",
    ").__ \n",
    "\n",
    "__When sampling is performed without replacement, it is called\n",
    "pasting.__\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
