{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistical Learning\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is Statistical Learning?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We try to determine the association between the input variables and output variables.\n",
    "\n",
    "Input variables are also known as *predictors, independent variables, features,* or sometimes just *variables*.\n",
    "\n",
    "Output variables are also known as *response* or *dependent variables*.\n",
    "\n",
    "Generally, we suppose a relation $$Y = f(X) + \\epsilon$$ where Y is the response, X is predictors, $f$ is some fixed but unknown function of p different predictors $X = (X_{1}, X_{2}, \\cdots, X_{p})$ and $\\epsilon$ is the general error term independent of X with mean error 0.\n",
    "\n",
    "In essence, statistical learning refers to a set of approaches for estimating $f$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why estimate $f$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two main reasons to estimate $f$:\n",
    "- *Prediction*\n",
    "- *Inference*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Prediction*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In many situations, a set of inputs X are readily available, but the output\n",
    "Y cannot be easily obtained. In this setting, since the error term averages\n",
    "to zero, we can predict Y using $$\\hat{Y} = \\hat{f}(X)$$\n",
    "where $\\hat{f}$ represents our estimate for $f$, and $\\hat{Y}$ represents the resulting prediction for $Y$.\n",
    "\n",
    "In this setting, $\\hat{f}$ is generally treated as *black box*, in the sense that we are generally not concerned with the exact form of $\\hat{f}$, provided that it yields accurate predictions of Y."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy of $\\hat{Y}$ as a prediction of $Y$ depends on two quantities:\n",
    "- *reducible error*\n",
    "- *irreducible error*\n",
    "\n",
    "In general,\n",
    "$\\hat{f}$ will not be a perfect estimate for $f$, and this inaccuracy will introduce\n",
    "some error. This error is reducible because we can potentially improve the\n",
    "accuracy of $\\hat{f}$ by using the most appropriate statistical learning technique to\n",
    "estimate $f$. However, even if it were possible to form a perfect estimate for\n",
    "$f$, so that our estimated response took the form $\\hat{Y} = f(X)$, our prediction\n",
    "would still have some error in it! This is because Y is also a function of\n",
    "$\\epsilon$, which, by definition, cannot be predicted using X. Therefore, variability\n",
    "associated with $\\epsilon$ also affects the accuracy of our predictions. This is known\n",
    "as the irreducible error, because no matter how well we estimate $f$, we\n",
    "cannot reduce the error introduced by $\\epsilon$.\n",
    "\n",
    "Consider a given estimate $\\hat{f}$ and a set of predictors $X$, which yields the prediction $\\hat{Y} = \\hat{f}(X)$. Assume for a moment that both $\\hat{f}$ and $X$ are fixed. Then, it is easy to show that\n",
    "$$E(Y - \\hat{Y})^{2} = E[f(X) + \\epsilon - \\hat{f}(X)]^{2} = [f(X) - \\hat{f}(X)]^{2} + Var(\\epsilon)$$\n",
    "where $E(Y - \\hat{Y})^{2}$ represents the average, or expected value, of the squared\n",
    "difference between the predicted and actual value of Y, and Var($\\epsilon$) represents the variance associated with the error term $\\epsilon$ which is the irreducible error while $[f(X) - \\hat{f}(X)]^{2}$ is the reducible error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Inference*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are often faced with the situation where we wish to understand the way how $Y$ changes as a function of $X_{1}, \\cdots, X_{p}$.\n",
    "Now, $\\hat{f}$ cannot be treated as a black box.\n",
    "\n",
    "Many questions may be followed:\n",
    "- Which predictors are associated with the response?\n",
    "- What is the relationship between the response and each predictor?\n",
    "- Can the relationship between Y and each predictor be adequately summarized using a linear equation, or is the relationship more complicated?\n",
    "\n",
    "Depending on whether our ultimate goal is prediction, inference, or a\n",
    "combination of the two, different methods for estimating f may be appropriate.\n",
    "For example, linear models allow for relatively simple and interpretable inference, \n",
    "but may not yield as accurate predictions as some other\n",
    "approaches. In contrast, some of the highly non-linear approaches can potentially provide quite \n",
    "accurate predictions for Y, but this comes at the expense of a less interpretable\n",
    "model for which inference is more challenging."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How do we estimate $f$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two main methods to estimate $f$:\n",
    "- Parametric methods (E.g. Linear model fit)\n",
    "- Non-Parametric methods (E.g. Thin-plate spline)\n",
    "\n",
    "Parametric methods often make explicit assumptions about the functional form of $f$ like that of the shape of the model and then using the training data to fit or train the model. Non-parametric methods do not make explicit assumptions about the functional form of $f$. This provides a greater flexibility over the shape of the model and often leads to more accurate shape of $f$.\n",
    "\n",
    "The potential disadvantage of a parametric approach is that\n",
    "the model we choose will usually not match the true\n",
    "unknown form of $f$. If the chosen model is too far from the true $f$, then\n",
    "our estimate will be poor. We can try to address this problem by choosing flexible models that can fit many different possible functional forms for $f$. But in general, fitting a more flexible model requires estimating a greater number of parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tradeoff between Predicition Accuracy and Model Interpretability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear regression is a relatively inflexible approach, because it can only generate linear functions.\n",
    "Other methods, such as the thin plate splines are considerably more flexible because they can generate a much wider range of possible shapes to estimate $f$.\n",
    "\n",
    "*Why would we ever choose to use a more restrictive method instead of a very flexible approach?*\n",
    "\n",
    "There are several reasons that we might prefer a more restrictive model.\n",
    "If we are mainly interested in inference, then restrictive models are much\n",
    "more interpretable. For instance, when inference is the goal, the linear\n",
    "model may be a good choice since it will be quite easy to understand\n",
    "the relationship between $Y$ and $X_{1}, X_{2}, \\cdots, X_{p}$.\n",
    "\n",
    "We have established that when inference is the goal, there are clear advantages to using simple and relatively inflexible statistical learning methods. In some settings, however, we are only interested in prediction, and the interpretability of the predictive model is simply not of interest. For instance, if we seek to develop an algorithm to predict the price of a stock, our sole requirement for the algorithm is that it predict accurately, interpretability is not a concern. In this setting, we might expect that it will be best to use the most flexible model available.\n",
    "\n",
    "*In general, as the flexibility of a method increases, its interpretability decreases.*\n",
    "\n",
    "![](./img/tradeoff.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Supervised vs. Unsupervised Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most statistical learning problems fall into one of two categories:\n",
    "- Supervised\n",
    "- Unsupervised\n",
    "\n",
    "In supervised learning, there is an associated response measurement $y_{i}$ for each predictor measurement $x_{i},\\ i = 1, \\cdots, n$.\n",
    "In contrast, unsupervised learning is a somewhat challenging situation wherein for each observation $i = 1, \\cdots, n$, we observe a vector of measurements $x_{i}$, but no associated response $y_{i}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression vs. Classification Problems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variables can be characterized as either quantitative or qualitative. Quantitative variables take on numerical values. Examples include a person’s age, height, or income, the value of a house, and the price of a stock. In contrast, qualitative variables take on values in one of K different classes, or categories. Examples of qualitative variables include a person’s gender (male or female), the brand of product purchased (brand A, B, or C), whether a person defaults on a debt (yes or no), or a cancer diagnosis (Acute Myelogenous Leukemia, Acute\n",
    "Lymphoblastic Leukemia, or No Leukemia). We tend to refer to problems with a quantitative response as regression problems, while those involving a qualitative response are often referred to as classification problems.\n",
    "\n",
    "However, whether the predictors are qualitative or quantitative is generally considered less important."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accessing Model Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In regression settings, the most common approach for quantifying estimates is the mean squared error is given by,\n",
    "$$MSE = \\frac{1}{n}\\sum_{i = 1}^{n}{(y_{i} - \\hat{f}(x_{i}))^{2}}$$\n",
    "where $\\hat{f}(x_{i})$ is the prediction that $\\hat{f}$ gives for the $i^{th}$ observation. Hence, we could compute test average squared prediction error $$Ave\\left(y_{0} - \\hat{f}\\left(x_{0}\\right)\\right)^{2}$$ The MSE will be small if the predicted responses are very close to the true responses, and will be large if for some of the observations, the predicted and true responses differ substantially.\n",
    "\n",
    "In classification settings, the most common approach for quantifying estimates is given by,\n",
    "$$E = \\frac{1}{n}\\sum_{i = 1}^{n}I\\left(y_{i} \\neq \\hat{y}_{i}\\right)$$\n",
    "where $I\\left(y_{i} \\neq \\hat{y}_{i}\\right)$ is the indicator variable which equals 1 if $y_{i} \\neq \\hat{y}_{i}$ else 0. This would be our training error rate and thus our test error rate would be $$Ave\\left(I\\left(y_{i} \\neq \\hat{y}_{i}\\right)\\right)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bias-Variance Trade-off"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expected test MSE, for a given value $x_{0}$, can always be decomposed into the sum of three fundamental quantities:\n",
    "- variance of $\\hat{f}(x_{0})$\n",
    "- squared bias of $\\hat{f}(x_{0})$\n",
    "- variance of error terms $\\epsilon$\n",
    "\n",
    "$$E\\left(y_{0} - \\hat{f}\\left(x_{0}\\right)\\right)^{2} = Var\\left(\\hat{f}\\left(x_{0}\\right)\\right) + \\left[Bias\\left(\\hat{f}\\left(x_{0}\\right)\\right)\\right] + Var\\left(\\epsilon\\right)$$\n",
    "\n",
    "Here, $E\\left(y_{0} - \\hat{f}\\left(x_{0}\\right)\\right)^{2}$ defines the *expected test MSE*.\n",
    "\n",
    "We need to minimize the expected test error or the reducible error by achieving a *low variance* and *low bias*. Since, both variance and squared bias are non-negative quantities, the expected test MSE can never lie below $Var\\left(\\epsilon\\right)$ which is the irreducible.\n",
    "\n",
    "*Variance* refers to the amount of by which $\\hat{f}$ would change if we estimated it using a different training dataset. *Bias* refers to the error that is introduced by approximating a real-life problem, which may be extremely complicated, by a much simpler model. For example, linear regression assumes that there is a linear relationship between $Y$ and $X_{1}, X_{2}, \\cdots, X_{p}$. It is unlikely that any real-life problem truly has such a simple linear relationship, and so performing linear regression will undoubtedly result in some bias in the estimate of $f$. Generally, more flexible methods have high variance and low bias while less flexible methods will have a low variance and high bias."
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
