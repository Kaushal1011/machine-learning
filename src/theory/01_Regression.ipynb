{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistical Learning\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contents\n",
    "- [Linear Regression](#linreg)\n",
    "- [Simple Linear Regression](#simlinreg)\n",
    "- [Estimating the coefficients](#estcoef)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"linreg\"></a>\n",
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the **Advertising** dataset. It displays *sales* of a particular product\n",
    "as a function of advertising budgets for *TV*, *radio* and *newspaper* media.\n",
    "Here are a few important questions that we might seek to address:\n",
    "- Is there a relationship between advertising budget and sales?\n",
    "- How strong is the relationship between advertising budget and sales?\n",
    "- Which media contribute to sales?\n",
    "- How accurately can we estimate the effect of each medium on sales?\n",
    "- How accurately can we predict future sales?\n",
    "- Is the relationship linear?\n",
    "- Is there synergy/interaction among the advertising media?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"simlinreg\"></a>\n",
    "## Simple Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is a very straightforward approach for predicting a quantitative response Y on the basis of a single predictor variable $X$. It assumes that there is approximately a linear relationship between $X$ and $Y$. Mathematically, we can write this linear relationship as\n",
    "$$Y \\approx \\beta_{0} + \\beta_{1}X$$\n",
    "where $\\beta_{0}$ is the intercept and $\\beta_{1}$ is the slope term in linear model.\n",
    "They are known as model *coefficients* or *parameters*.\n",
    "Suppose, *sales* regresses onto *TV*, it can be written as\n",
    "$$sales \\approx \\beta_{0} + \\beta_{1} \\times TV$$\n",
    "Once we have our training data to produce estimates $\\hat{\\beta_{0}}$ and $\\hat{\\beta_{1}}$ for the model coefficients,\n",
    "we predict the future sales on the basis of particular value of TV advertising by computing\n",
    "$$\\hat{y} = \\hat{\\beta_{0}} + \\hat{\\beta_{1}}x$$\n",
    "where $\\hat{y}$ is the prediction of $Y$ on the basis of $X = x$.\n",
    "We use $\\hat{}$ to denote the estimated value for an unknown parameter or coefficient, or to denote the predicted value of the response."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"estcoef\"></a>\n",
    "### Estimating the coefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In practice, $\\beta_{0}$ and $\\beta_{1}$ are unknown.\n",
    "Our goal is to obtain coefficient estimates $\\hat{\\beta_{0}}$ and $\\hat{\\beta_{1}}$ such that the linear model\n",
    "$y_{i} \\approx \\hat{\\beta_{0}} + \\hat{\\beta_{1}}x_{i}$ for $i = 1, \\cdots, n$ fits the available data well.\n",
    "In other words, we want to find an intercept $\\hat{\\beta_{0}}$ and slope $\\hat{\\beta_{1}}$ such that the resulting line is as close as possible to the $n$ data points."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let $\\hat{y_{i}} = \\hat{\\beta_{0}} + \\hat{\\beta_{1}}x_{i}$ be the prediction for $Y$ based on the $i^{th}$ value of $X$.\n",
    "Then $e_{i} = y_{i} - \\hat{y_{i}}$ represents the $i^{th}$ residual. Thus the *residual sum of squares (RSS)* is\n",
    "$$RSS = {e_{1}}^{2} + {e_{2}}^{2} + \\cdots + {e_{n}}^{2}$$\n",
    "This is equivalent to\n",
    "$$RSS = \\left(y_{1} - \\hat{\\beta_{0}} - \\hat{\\beta_{1}}x_{1}\\right)^{2} +\n",
    "        \\left(y_{2} - \\hat{\\beta_{0}} - \\hat{\\beta_{1}}x_{2}\\right)^{2} +\n",
    "        \\cdots +\n",
    "        \\left(y_{n} - \\hat{\\beta_{0}} - \\hat{\\beta_{1}}x_{n}\\right)^{2}$$\n",
    "The least squares approach chooses $\\hat{\\beta_{0}}$ and $\\hat{\\beta_{1}}$ to minimize the RSS which are given by\n",
    "$$\\hat{\\beta_{1}} = \\frac{\\sum_{i = 1}^{n}\\left(x_{i} - \\bar{x}\\right)\\left(y_{i} - \\bar{y}\\right)}\n",
    "                        {\\sum_{i = 1}^{n}\\left(x_{i} - \\bar{x}\\right)^{2}}$$\n",
    "\n",
    "$$\\hat{\\beta_{0}} = \\bar{y} - \\hat{\\beta_{1}}\\bar{x}$$\n",
    "where $$\\bar{y} = \\frac{1}{n}\\sum_{i = 1}^{n}y_{i}$$ and $$\\bar{x} = \\frac{1}{n}\\sum_{i = 1}^{n}x_{i}$$ are the sample means.\n",
    "This defines the *least squares coefficient estimates* for simple linear regression."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
